{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039596b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seal import *\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "parms = EncryptionParameters(scheme_type.bfv)\n",
    "poly_modulus_degree = 8192\n",
    "parms.set_poly_modulus_degree(poly_modulus_degree)\n",
    "parms.set_coeff_modulus(CoeffModulus.BFVDefault(2048))\n",
    "parms.set_plain_modulus(2**19)\n",
    "context = SEALContext(parms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbfbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(tensor, unit):\n",
    "    flattened = tensor.reshape(-1)\n",
    "    serialized = [flattened[i*unit:(i+1)*unit] for i in range(1+int(flattened.shape[0]/unit))]\n",
    "    return serialized, tensor.shape\n",
    "\n",
    "def scale_and_round(vector, scale_factor, shift_amount):\n",
    "    a_vector = vector+shift_amount\n",
    "    a_vector = a_vector*scale_factor\n",
    "    return a_vector.int()\n",
    "\n",
    "def recon(vector_list, shape, scale_factor):\n",
    "    vector = torch.concat(vector_list,axis=-1)\n",
    "    return (vector.reshape(shape))/scale_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6703b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_string(np_array):\n",
    "    x = np.zeros([poly_modulus_degree])\n",
    "    # x[:len(np_array)].shape\n",
    "    x[:len(np_array)] = np_array\n",
    "    res = \"\"\n",
    "    for i, v in enumerate(x[::-1]):\n",
    "        i = poly_modulus_degree-i-1\n",
    "        if i != 0 and v > 0:\n",
    "            res += f\"{hex(int(v))}\"[2:]+f\"x^{i} + \"\n",
    "        elif i==0:\n",
    "            res += f\"{hex(int(v))}\"[2:]\n",
    "    return res\n",
    "def string_to_numpy(hex_poly):\n",
    "    elem = hex_poly.split(\" + \")\n",
    "    if('x' not in elem[-1]):\n",
    "        elem[-1] += \"x^0\"\n",
    "    values = [int(\"0x\"+e.split(\"x\")[0],16) for e in elem]\n",
    "    keys = [int(e.split(\"x^\")[1]) for e in elem]\n",
    "    results = torch.zeros([poly_modulus_degree],dtype=int)\n",
    "    for k,v in zip(keys, values):\n",
    "        results[k] = v\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d46e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class PythonParty(Party):\n",
    "    def __init__(self,model,*args,**kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "    def __call__(self,x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def get_grad(self):\n",
    "        \"\"\"return a dictionary that having model gradient information\"\"\"\n",
    "        res = defaultdict(None)\n",
    "        for i,layer in enumerate(self.model.layers()):\n",
    "            res[f\"{i}_weight\"] = layer.weight.grad\n",
    "            res[f\"{i}_bias\"] = layer.bias.grad\n",
    "        return res\n",
    "    def encrypt_tensor(self, tensor, scale, shamt):\n",
    "        ser_list, ori_shape = serialize(tensor, poly_modulus_degree)\n",
    "        if(ser_list[-1].shape[0]==0): ser_list = ser_list[:-1]\n",
    "        ser_list = [scale_and_round(v, scale, shamt) for v in ser_list]\n",
    "        ser_list = [Plaintext(numpy_to_string(v)) for v in ser_list]\n",
    "        print(ser_list)\n",
    "        ser_list_encrypted = [self.encrypt(st) for st in ser_list]\n",
    "        return ser_list_encrypted, ori_shape\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a3b0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonProtocol(Protocol):\n",
    "    def __init__(self, evaluator, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.evaluator = evaluator\n",
    "    def secure_add(self, tensor_a, tensor_b, party_a, party_b, scale=100, shamt=0):\n",
    "        ctx_a_list, shape_a = party_a.encrypt_tensor(tensor_a, scale, shamt)\n",
    "        ctx_b_list, shape_b = party_b.encrypt_tensor(tensor_b, scale, shamt)\n",
    "        res = []\n",
    "        for ctx_a, ctx_b in zip(ctx_a_list, ctx_b_list):\n",
    "            ctx_res = self.evaluator.add(ctx_a, ctx_b)\n",
    "            dec = proto.decrypt(ctx_res)\n",
    "            res.append(string_to_numpy(dec.to_string()))\n",
    "        res = recon(res, shape_a, scale)-2*shamt\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec7a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, layer1=128, layer2=256, output=10):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, layer1)\n",
    "        self.layer2 = nn.Linear(layer1, layer2)\n",
    "        self.layer3 = nn.Linear(layer2, output)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "    def layers(self):\n",
    "        return [self.layer1, self.layer2, self.layer3]\n",
    "    def forward(self,x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.layer2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.layer3(x)\n",
    "        x = nn.functional.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7acb677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATHERING\n",
      "[<seal.Plaintext object at 0x7f9b0dbf9170>, <seal.Plaintext object at 0x7f9b0dc38b70>]\n",
      "[<seal.Plaintext object at 0x7f9b0dbf9170>, <seal.Plaintext object at 0x7f9b0dc38b70>]\n",
      "Add time:  0.09780526161193848\n",
      "tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "t = 4\n",
    "val = Evaluator(context)\n",
    "proto = PythonProtocol(val,context,t)\n",
    "\n",
    "parties = []\n",
    "for i in range(n):\n",
    "    p = PythonParty(Classifier(),context)\n",
    "    parties.append(p)\n",
    "    p.register(proto)\n",
    "for i in range(n):\n",
    "    proto.calculate_share(i+1)\n",
    "proto.generate_pk()\n",
    "parties[1].update_pk()\n",
    "x = torch.rand([2,8192])\n",
    "y = 0.5-x\n",
    "t = time.time()\n",
    "z = proto.secure_add(x,y,parties[2], parties[5], scale=100000, shamt=1)\n",
    "print(\"Add time: \", time.time()-t)\n",
    "print(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5d4bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<seal.Plaintext object at 0x7f9b09b3bef0>, <seal.Plaintext object at 0x7f9b09b25ef0>, <seal.Plaintext object at 0x7f9b09ba2670>, <seal.Plaintext object at 0x7f9b09b1a7f0>]\n",
      "[<seal.Plaintext object at 0x7f9b09b3bef0>, <seal.Plaintext object at 0x7f9b09b25ef0>, <seal.Plaintext object at 0x7f9b09ba2670>, <seal.Plaintext object at 0x7f9b09b1a7f0>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0071)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = parties[0].get_grad()[\"1_weight\"]\n",
    "second = parties[1].get_grad()[\"1_weight\"]\n",
    "proto.secure_add(first, second, parties[0],parties[1], scale=100000,shamt=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ff6ced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0071)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(first+second).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2baad369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "m2 = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "346356cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_634/1948082911.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand([1,784])\n",
    "cr = nn.CrossEntropyLoss()\n",
    "y = torch.ones([1],dtype=torch.uint8)\n",
    "z = parties[0](x)\n",
    "z_ = parties[1](x)\n",
    "loss = cr(z, y)\n",
    "l2 = cr(z_,y)\n",
    "loss.backward()\n",
    "l2.backward()\n",
    "# model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee9bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(tensor, unit):\n",
    "    flattened = tensor.reshape(-1)\n",
    "    serialized = [flattened[i*unit:(i+1)*unit] for i in range(1+int(flattened.shape[0]/unit))]\n",
    "    return serialized, tensor.shape\n",
    "\n",
    "def scale_and_round(vector, scale_factor, shift_amount):\n",
    "    a_vector = vector+shift_amount\n",
    "    a_vector = a_vector*scale_factor\n",
    "    return a_vector.int()\n",
    "\n",
    "def recon(vector_list, shape, scale_factor):\n",
    "    vector = torch.concat(vector_list,axis=-1)\n",
    "    return (vector.reshape(shape))/scale_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdd9c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85ab158b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_634/58950648.py:8: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n"
     ]
    }
   ],
   "source": [
    "data = read_idx(\"MNIST/raw/train-images-idx3-ubyte\")\n",
    "label = read_idx(\"MNIST/raw/train-labels-idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4940913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d817389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte     train-images-idx3-ubyte\r\n",
      "\u001b[0m\u001b[01;31mt10k-images-idx3-ubyte.gz\u001b[0m  \u001b[01;31mtrain-images-idx3-ubyte.gz\u001b[0m\r\n",
      "t10k-labels-idx1-ubyte     train-labels-idx1-ubyte\r\n",
      "\u001b[01;31mt10k-labels-idx1-ubyte.gz\u001b[0m  \u001b[01;31mtrain-labels-idx1-ubyte.gz\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls MNIST/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9839ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "for i in range(4):\n",
    "    axs[i//2,i%2].imshow(data[i,:,:])\n",
    "print(label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d52a412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train(protocol, parties, dataset, labels, n_rounds=1, party_per_round=5):\n",
    "    for ruond in range(n_rounds):\n",
    "        chosen_ps_id = random.sample(range(len(parties)), party_per_round)\n",
    "        chosen_ps = [(i,parties[i]) for i in chosen_ps_id]\n",
    "        grad_infos = []\n",
    "        total = defaultdict(None)\n",
    "        for c, (i, p) in enumerate(chosen_ps):\n",
    "            datas = dataset[i]\n",
    "            labls = labels[i]\n",
    "            pred = p(datas)\n",
    "            local_loss = cr(pred, labls)\n",
    "            local_loss.backward()\n",
    "            #             grad_infos.append([i,p.get_grad()])\n",
    "            infos = p.get_grad()\n",
    "            if c == 0:\n",
    "                for k,v in infos.items():\n",
    "                    total[k] = v\n",
    "            else:\n",
    "                for k,v in infos.items():\n",
    "                    total[k] = proto.secure_add(v,total[k],parties[0],parties[i],scale=10000,shamt=10)\n",
    "        \n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2518a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dats = [None]*len(parties)\n",
    "lbls = [None]*len(parties)\n",
    "for i, p in enumerate(parties):\n",
    "    dats[i] = torch.Tensor(data[i::len(parties),:,:])\n",
    "    lbls[i] = torch.Tensor(label[i::len(parties)]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4d7bfa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_634/1948082911.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = nn.functional.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<seal.Plaintext object at 0x7f9b0822aeb0>, <seal.Plaintext object at 0x7f9b097655f0>, <seal.Plaintext object at 0x7f9b0822aef0>, <seal.Plaintext object at 0x7f9b08226970>, <seal.Plaintext object at 0x7f9b08226cf0>, <seal.Plaintext object at 0x7f9b08226e70>, <seal.Plaintext object at 0x7f9b082268b0>, <seal.Plaintext object at 0x7f9b08226d70>, <seal.Plaintext object at 0x7f9b097149b0>, <seal.Plaintext object at 0x7f9b08226df0>, <seal.Plaintext object at 0x7f9b795469f0>, <seal.Plaintext object at 0x7f9b08226cb0>, <seal.Plaintext object at 0x7f9b08226e30>]\n",
      "[<seal.Plaintext object at 0x7f9b097655f0>, <seal.Plaintext object at 0x7f9b795469f0>, <seal.Plaintext object at 0x7f9b097149b0>, <seal.Plaintext object at 0x7f9b0822aef0>, <seal.Plaintext object at 0x7f9b0822aeb0>, <seal.Plaintext object at 0x7f9b082268b0>, <seal.Plaintext object at 0x7f9b08226970>, <seal.Plaintext object at 0x7f9b08226df0>, <seal.Plaintext object at 0x7f9b0826d370>, <seal.Plaintext object at 0x7f9b08226cf0>, <seal.Plaintext object at 0x7f9b09757030>, <seal.Plaintext object at 0x7f9b08226cb0>, <seal.Plaintext object at 0x7f9b082403b0>]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 784]' is invalid for input of size 106496",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbls\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [83]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(protocol, parties, dataset, labels, n_rounds, party_per_round)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m infos\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 21\u001b[0m         total[k] \u001b[38;5;241m=\u001b[39m \u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecure_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparties\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mPythonProtocol.secure_add\u001b[0;34m(self, tensor_a, tensor_b, party_a, party_b, scale, shamt)\u001b[0m\n\u001b[1;32m     11\u001b[0m     dec \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mdecrypt(ctx_res)\n\u001b[1;32m     12\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(string_to_numpy(dec\u001b[38;5;241m.\u001b[39mto_string()))\n\u001b[0;32m---> 13\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrecon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mshamt\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mrecon\u001b[0;34m(vector_list, shape, scale_factor)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecon\u001b[39m(vector_list, shape, scale_factor):\n\u001b[1;32m     12\u001b[0m     vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat(vector_list,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m/\u001b[39mscale_factor\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 784]' is invalid for input of size 106496"
     ]
    }
   ],
   "source": [
    "train(proto, parties, dats, lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04369399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
